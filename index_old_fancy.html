<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Kai Zhen - Ph.D. Candidate at Indiana University</title>
		<meta charset="utf-8" />
		<link rel="shortcut icon" href="images/pumpkin.jpg">
		<meta name="description" content="Ph.D. Candidate in Computer Science and Cognitive Science at Indiana University. Future Applied Scientist at Amazon. Proud to Be A Hoosier.">
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		
		<link rel="stylesheet" href="assets/css/sub.css" />
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-157962260-1"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-157962260-1');
		</script>

		<style type="text/css">.row{border-bottom:solid 1px transparent}.row>*{float:left}.row:after,.row:before{content:"";display:block;clear:both;height:0}.row.uniform>*>:first-child{margin-top:0}.row.uniform>*>:last-child{margin-bottom:0}.\31 2u,.\31 2u\24{width:100%;clear:none;margin-left:0}.\31 1u,.\31 1u\24{width:91.6666666667%;clear:none;margin-left:0}.\31 0u,.\31 0u\24{width:83.3333333333%;clear:none;margin-left:0}.\39 u,.\39 u\24{width:75%;clear:none;margin-left:0}.\38 u,.\38 u\24{width:66.6666666667%;clear:none;margin-left:0}.\37 u,.\37 u\24{width:58.3333333333%;clear:none;margin-left:0}.\36 u,.\36 u\24{width:50%;clear:none;margin-left:0}.\35 u,.\35 u\24{width:41.6666666667%;clear:none;margin-left:0}.\34 u,.\34 u\24{width:33.3333333333%;clear:none;margin-left:0}.\33 u,.\33 u\24{width:25%;clear:none;margin-left:0}.\32 u,.\32 u\24{width:16.6666666667%;clear:none;margin-left:0}.\31 u,.\31 u\24{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24+*,.\31 1u\24+*,.\31 0u\24+*,.\39 u\24+*,.\38 u\24+*,.\37 u\24+*,.\36 u\24+*,.\35 u\24+*,.\34 u\24+*,.\33 u\24+*,.\32 u\24+*,.\31 u\24+*{clear:left;}.\-11u{margin-left:91.6666666667%}.\-10u{margin-left:83.3333333333%}.\-9u{margin-left:75%}.\-8u{margin-left:66.6666666667%}.\-7u{margin-left:58.3333333333%}.\-6u{margin-left:50%}.\-5u{margin-left:41.6666666667%}.\-4u{margin-left:33.3333333333%}.\-3u{margin-left:25%}.\-2u{margin-left:16.6666666667%}.\-1u{margin-left:8.3333333333%}</style><style type="text/css">.container{margin-left:auto;margin-right:auto;width:1200px}.container.\31 25\25{width:100%;max-width:1500px;min-width:1200px}.container.\37 5\25{width:900px}.container.\35 0\25{width:600px}.container.\32 5\25{width:300px}</style><style type="text/css">.row>*{padding:50px 0 0 50px}.row{margin:-50px 0 -1px -50px}.row.uniform>*{padding:50px 0 0 50px}.row.uniform{margin:-50px 0 -1px -50px}.row.\32 00\25>*{padding:100px 0 0 100px}.row.\32 00\25{margin:-100px 0 -1px -100px}.row.uniform.\32 00\25>*{padding:100px 0 0 100px}.row.uniform.\32 00\25{margin:-100px 0 -1px -100px}.row.\31 50\25>*{padding:75px 0 0 75px}.row.\31 50\25{margin:-75px 0 -1px -75px}.row.uniform.\31 50\25>*{padding:75px 0 0 75px}.row.uniform.\31 50\25{margin:-75px 0 -1px -75px}.row.\35 0\25>*{padding:25px 0 0 25px}.row.\35 0\25{margin:-25px 0 -1px -25px}.row.uniform.\35 0\25>*{padding:25px 0 0 25px}.row.uniform.\35 0\25{margin:-25px 0 -1px -25px}.row.\32 5\25>*{padding:12.5px 0 0 12.5px}.row.\32 5\25{margin:-12.5px 0 -1px -12.5px}.row.uniform.\32 5\25>*{padding:12.5px 0 0 12.5px}.row.uniform.\32 5\25{margin:-12.5px 0 -1px -12.5px}.row.\30 \25>*{padding:0}.row.\30 \25{margin:0 0 -1px 0}</style><style type="text/css">.\31 2u\28 global\29,.\31 2u\24\28 global\29{width:100%;clear:none;margin-left:0}.\31 1u\28 global\29,.\31 1u\24\28 global\29{width:91.6666666667%;clear:none;margin-left:0}.\31 0u\28 global\29,.\31 0u\24\28 global\29{width:83.3333333333%;clear:none;margin-left:0}.\39 u\28 global\29,.\39 u\24\28 global\29{width:75%;clear:none;margin-left:0}.\38 u\28 global\29,.\38 u\24\28 global\29{width:66.6666666667%;clear:none;margin-left:0}.\37 u\28 global\29,.\37 u\24\28 global\29{width:58.3333333333%;clear:none;margin-left:0}.\36 u\28 global\29,.\36 u\24\28 global\29{width:50%;clear:none;margin-left:0}.\35 u\28 global\29,.\35 u\24\28 global\29{width:41.6666666667%;clear:none;margin-left:0}.\34 u\28 global\29,.\34 u\24\28 global\29{width:33.3333333333%;clear:none;margin-left:0}.\33 u\28 global\29,.\33 u\24\28 global\29{width:25%;clear:none;margin-left:0}.\32 u\28 global\29,.\32 u\24\28 global\29{width:16.6666666667%;clear:none;margin-left:0}.\31 u\28 global\29,.\31 u\24\28 global\29{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24\28 global\29+*,.\31 1u\24\28 global\29+*,.\31 0u\24\28 global\29+*,.\39 u\24\28 global\29+*,.\38 u\24\28 global\29+*,.\37 u\24\28 global\29+*,.\36 u\24\28 global\29+*,.\35 u\24\28 global\29+*,.\34 u\24\28 global\29+*,.\33 u\24\28 global\29+*,.\32 u\24\28 global\29+*,.\31 u\24\28 global\29+*{clear:left;}.\-11u\28 global\29{margin-left:91.6666666667%}.\-10u\28 global\29{margin-left:83.3333333333%}.\-9u\28 global\29{margin-left:75%}.\-8u\28 global\29{margin-left:66.6666666667%}.\-7u\28 global\29{margin-left:58.3333333333%}.\-6u\28 global\29{margin-left:50%}.\-5u\28 global\29{margin-left:41.6666666667%}.\-4u\28 global\29{margin-left:33.3333333333%}.\-3u\28 global\29{margin-left:25%}.\-2u\28 global\29{margin-left:16.6666666667%}.\-1u\28 global\29{margin-left:8.3333333333%}.\31 2u\28 desktop\29,.\31 2u\24\28 desktop\29{width:100%;clear:none;margin-left:0}.\31 1u\28 desktop\29,.\31 1u\24\28 desktop\29{width:91.6666666667%;clear:none;margin-left:0}.\31 0u\28 desktop\29,.\31 0u\24\28 desktop\29{width:83.3333333333%;clear:none;margin-left:0}.\39 u\28 desktop\29,.\39 u\24\28 desktop\29{width:75%;clear:none;margin-left:0}.\38 u\28 desktop\29,.\38 u\24\28 desktop\29{width:66.6666666667%;clear:none;margin-left:0}.\37 u\28 desktop\29,.\37 u\24\28 desktop\29{width:58.3333333333%;clear:none;margin-left:0}.\36 u\28 desktop\29,.\36 u\24\28 desktop\29{width:50%;clear:none;margin-left:0}.\35 u\28 desktop\29,.\35 u\24\28 desktop\29{width:41.6666666667%;clear:none;margin-left:0}.\34 u\28 desktop\29,.\34 u\24\28 desktop\29{width:33.3333333333%;clear:none;margin-left:0}.\33 u\28 desktop\29,.\33 u\24\28 desktop\29{width:25%;clear:none;margin-left:0}.\32 u\28 desktop\29,.\32 u\24\28 desktop\29{width:16.6666666667%;clear:none;margin-left:0}.\31 u\28 desktop\29,.\31 u\24\28 desktop\29{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24\28 desktop\29+*,.\31 1u\24\28 desktop\29+*,.\31 0u\24\28 desktop\29+*,.\39 u\24\28 desktop\29+*,.\38 u\24\28 desktop\29+*,.\37 u\24\28 desktop\29+*,.\36 u\24\28 desktop\29+*,.\35 u\24\28 desktop\29+*,.\34 u\24\28 desktop\29+*,.\33 u\24\28 desktop\29+*,.\32 u\24\28 desktop\29+*,.\31 u\24\28 desktop\29+*{clear:left;}.\-11u\28 desktop\29{margin-left:91.6666666667%}.\-10u\28 desktop\29{margin-left:83.3333333333%}.\-9u\28 desktop\29{margin-left:75%}.\-8u\28 desktop\29{margin-left:66.6666666667%}.\-7u\28 desktop\29{margin-left:58.3333333333%}.\-6u\28 desktop\29{margin-left:50%}.\-5u\28 desktop\29{margin-left:41.6666666667%}.\-4u\28 desktop\29{margin-left:33.3333333333%}.\-3u\28 desktop\29{margin-left:25%}.\-2u\28 desktop\29{margin-left:16.6666666667%}.\-1u\28 desktop\29{margin-left:8.3333333333%}</style>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
			<link rel="stylesheet" href="css/style-desktop.css" />
		</noscript>

	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="#top">Home</a></li>			
					<li><a href="http://www.kaizhen.us/cv.html">Curriculum Vitae</a></li>		
					<li><a href="#portfolio">Research Projects</a></li>					
					<!--<li><a href="./developing-kai/index.html">Blog</a></li>-->
					<li><a href="#contact">Contact</a></li>

				</ul>
			</nav>

		<!-- Home -->
			<article id="top" class="wrapper style1">
				<div class="container">
					<div class="row">
						<!--<div class="col-4 col-5-large col-13-medium">-->
						<div align="center">
    <img src="1419252313.jpg" width="732" height="549" alt="kai">
    <br>
    <b><font size="6">Kai</font></b>
  </div>
						<div class="col-2 col-7-large col-12-medium">							
							<span class="image fit"><img src="images/head.jpg" style="width: 5vw; min-width: 200px;" /></span>
							<center>
								<figcaption>
									<!--<h3><strong>KAI ZHEN</strong></h3>			-->
									
								<!--</figcaption>
								<h4> <font color="990000">APPLIED MACHINE LEARNING</font> RESEARCHER BRINGING <font color="990000">AUDITORY INTELLIGENCE</font> TO <font color="990000">LOW-POWER DEVICES</font> THROUGH <font color="990000">CODING</font></h4>
								<h4> <font color="990000">Applied Machine Learning</font> Researcher for <font color="990000">On-Device </font> Auditory Intelligence </h4>
								<h4> <font color="990000"></font>Ph.D. Candidate (ABD) in Computer Science and Cognitive Science <font color="990000"> </font> at Indiana University </h4>-->
							</center>

						</div>
						<div class="col-10 col-10-large col-2-medium">							

							<center>
							<!--<h3><u> <a href="https://www.in.gov/gov/3232.htm"><font color="990000">Stay Home, </a>Stay Strong, Hoosiers!</font></u></h3>-->
							</center>

							<h3><strong>About Me</strong></h3>
							I'm Kai Zhen, and I'm in my final year of the Ph.D. program, advised by Prof. Minje Kim at Indiana University. 							
							My research is mainly on scalable and efficient speech and audio coding via techniques spanning the traditional digital signal processing domain and modern computational paradigm.
							<!--In my view, innovation does not only come from proposing brand new methodologies but reviving the conventional techniques as well.
							This is reflected in most of my projects as an joint effort spanning the traditional digital signal processing domain and modern computational paradigm.-->

							The six-year journey has also endowed me with opportunities including working with great companies such as LinkedIn and Amazon. My next play will be at Amazon Alexa as an applied scientist. <br>You may find my  <a href="http://kaizhen.us/cv.pdf">CV in PDF</a>.

							<br>
							<br>
							<h3><strong>Papers and Patents</strong></h3>

							<li> [C-004] <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<u>Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding</u>," <i>IEEE Signal Processing Letters</i>.
<br>
<a href="http://kaizhen.us/neural-audio-coding.html">[demo]</a>
<a href="http://kaizhen.us/pub/zhenk-spl.pdf">[pdf]</a>
<a href="http://kaizhen.us/pub/zhenk2020nac.txt">[bib]</a>
<a href="https://github.com/cocosci/pam-nac">[code]</a></li>

<li> [C-003] <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<u>Efficient And Scalable Neural Residual Waveform Coding with Collaborative Quantization</u>," <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, Barcelona, Spain, May 4-8, 2020. <br><a href="http://kaizhen.us/collaborative-quantization.html">[demo]</a><a href="http://kaizhen.us/pub/zhenk2020cq.pdf">[pdf]</a><a href="http://kaizhen.us/pub/cq.txt">[bib]</a><a href="https://github.com/cocosci/NSC">[code]</a></li>

<li> [C-002] <b>Kai Zhen</b>, Mi Suk Lee, Minje Kim. "<u>A Dual-Staged Context Aggregation Method towards Efficient End-To-End Speech Enhancement</u>,"  <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, Barcelona, Spain, May 4-8, 2020. <br><a href="http://kaizhen.us/speechenhancement.html">[demo]</a><a href="http://kaizhen.us/pub/dccrn.txt">[bib]</a></li>


<li> [C-001] <b>Kai Zhen</b>, Jongmo Sung, Mi Suk Lee, Seungkwon Beack, and Minje Kim, "<u>Cascaded Cross-Module Residual Learning towards Lightweight End-to-End Speech Coding</u>," In Proc. Annual Conference of the International Speech Communication Association (Interspeech)</i>, Graz, Austria, September 15-19, 2019. <br><a href="https://saige.sice.indiana.edu/research-projects/neural-audio-coding/">[demo]</a> <a href="http://kaizhen.us/pub/cmrl.txt">[bib]</a>
 </li>



<li> [P-004] Minje Kim, <b>Kai Zhen</b>, Seungkwon Beack, et al, "<u>Collaborative quantization for efficient and scalable neural waveform coding</u>," <i>US Patent Application, US 2020</i>.
</li>

<li> [P-003] Minje Kim, <b>Kai Zhen</b>, Mi Suk Lee, "<u>Apparatus and Method for Speech Processing Using a Densely Connected Hybrid Neural Network</u>," <i>US Patent Application, 2020</i>.
</li>

<li> [P-002] Minje Kim, <b>Kai Zhen</b>, Seungkwon Beack, et al, "<u>Audio Signal Encoding Method and Audio Signal Decoding Method, And Encoder And Decoder Performing the Same</u>," <i>US Patent Application, US20200135220A1</i>.
</li>


<li> [P-001] Minje Kim, Aswin Sivaraman, <b>Kai Zhen</b>, Jongmo Sung, et al, "<u>Audio signal encoding method and apparatus and audio signal decoding method and apparatus using psychoacoustic-based weighted error function</u>," <i>US Patent Application, US20190164052A1</i>.
</li>


<li> [W-004] <b>Kai Zhen</b>, Hieu Duy Nguyen, Feng-Ju (Claire) Chang, Athanasios Mouchtaris. Network Sparsification for On-Device ASR. Amazon Machine Learning Conference (AMLC) Workshop on Network Inference Optimization,2020.</a>
</li>


<li> [W-003] <b>Kai Zhen</b>, Aswin Sivaraman, Jongmo Sung, Minje Kim, "<u>On Psychoacoustically Weighted Cost Functions Towards Resource-efficient Deep Neural Networks for Speech Denoising</u>," <i>The 7th Annual Midwest Cognitive Science Conference</i>, Bloomington, IN, 2018. <a href="http://kaizhen.us/pub/zhen2018psychoacoustically.txt">[bib]</a>
</li>

<li> [W-002] Peter Miksza, Kevin Watson, <b>Kai Zhen</b>, Sanna Wager, Minje Kim, "<u>Relationships between expertsâ€™ subjective ratings of jazz improvisations and computational measures of melodic entropy</u>," <i>The Improvising Brain III: Cultural Variation and Analytical Techniques Symposium</i>, Atlanta, GA, in Feb, 2017.
</li>


<li> [W-001] <b>Kai Zhen</b> and David Crandall, "<u>Finding egocentric image topics through convolutional neural network based representations (extended abstract)</u>," <i>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop on Egocentric Computer Vision</i>, Las Vegas, US, June 26 - July 1, 2016. 
</li>



<br>

		<h3> Positions Held </h3>

<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/iu.png" border="0" width="80%">
</div>
<div class="9u">

<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Research Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Jan. 2018 - present</li>
		<li>Project: efficient end-to-end neural audio coding system</li>
		<li>Research group: <a href="http://saige.sice.indiana.edu/" target="_blank">Signals and AI Group in Engineering (SAIGE)</a></li>
	</ul>
</li></ul>	

<ul style="list-style-type: disc; margin-left: 2em;"> 
<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Teaching Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2015 - Dec. 2017</li>
		<li><a href="https://cs.indiana.edu/" target="_blank">Department of Computer Science</a> <br>(CSCI-C 343, CSCI-B 551, CSCI-B 657)</li>
		<li><a href="https://engineering.indiana.edu/" target="_blank">Intelligent Systems Engineering Department</a> <br>(ENGR E511, ENGR E533)</li>
	</ul>
</li></ul>
</div>
</div>



<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/amazon.png" border="0" width="80%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://developer.amazon.com/en-US/alexa/science" target="_blank">Amazon</a>: <b>Applied Scientist Intern</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2020 - Aug. 2020</li>						
		<li>Alexa Edge ML team</li>
		<li>Mentor: Hieu Duy Nguyen, Feng-ju (Claire) Chang</li>
		<li>Manager: Athanasios Mouchtaris</li>
		<li>Project: network compression for on-device ASR solutions</li>	
</li>							
						
	</ul>
</ul>	
</div>
</div>


<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/linkedin.svg" border="0" width="80%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2019 - Aug. 2019, Mountain View, CA </li>						
		<li>Ads AI group</li>							
		<li>Mentor: Lijun Peng, Hiroto Udagawa</li>		
		<li>Manager: Sara Smoot</li>							
		<li>Project: ads response rate prediction in wide-n-deep estimators and BERT</li>	
	</ul>
</li></ul>	
</div>
</div>

<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/linkedin.svg" border="0" width="80%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2018 - Aug. 2018, New York City, NY </li>						
		<li>Company standardization group</li>							
		<li>Mentor: Deirdre Hogan</li>	
		<li>Manager: Xiaoqiang Luo</li>	
		<li>Project: relevance ranking for resume builder with deep neural networks</li>	
	</ul>
</li></ul>	
</div>
</div>


<h3> Education </h3>

<br>


<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/iu.png" border="0" width="60%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Doctor of Philosophy</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2015 - present</li>
		<li><a href="https://cs.indiana.edu/" target="_blank"> Department of Computer Science</a></li>
		<li><a href="https://cogsci.indiana.edu/" target="_blank"> Cognitive Science Program</a></li>
		<li>Research group: <a href="http://saige.sice.indiana.edu/" target="_blank">Signals and AI Group in Engineering (SAIGE)</a></li>
		<li>Advised by Prof. Minje Kim</li>
		<li>Research Committee:</li>
		<ul style="list-style-type: circle; margin-left: 1em;"> 
		<li>Minje Kim (Chair, ISE @ IU)</li>
		<li>Robert Goldstone (CogSci @ IU)</li>
		<li>Donald Williamson (CS @ IU)</li>
		<li>Shen Yi (CogSci @ IU)</li>
		</ul>
		
	</ul>
</li></ul>	

</div>
</div>


<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/tsinghua2.png" border="0" width="60%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://www.tsinghua.edu.cn/publish/thu2018en/index.html" target="_blank">Tsinghua University</a>: <b>Master of Science</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2012 - Jun. 2015</li>						
		<li><a href="https://www.tsinghua.edu.cn/publish/csen/index.html" target="_blank">Department of Computer Science and Technology</a></li>
	</ul>

</ul>	
</div>
</div>


<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/xidian2.png" border="0" width="60%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://en.xidian.edu.cn/" target="_blank">Xidian University</a>: <b>Bachelor of Science</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2008 - Jun. 2012</li>						
		<li><a href="https://cs.xidian.edu.cn/" target="_blank">School of Software Engineering</a></li>
		<li>Graduated with Honors</li>
		
	</ul>
</ul>	</div>
</div>


							<!--
							<h3><strong>NEWS</strong></h3>
							<ul>
							 <li><h5>Paper on <a href="http://www.kaizhen.us/neural-audio-coding.html"><font color="990000">audio coding</font></a> to be published at <a href="https://ieeexplore.ieee.org/document/9265269"><font color="990000">IEEE Signal Processing Letters</font></a>.</h5></li>
							 	
							 	<li><h5>Gave a talk on my recent research activities  at <a href="https://www.youtube.com/watch?v=ybEwJKTaY0k"><font color="990000">Microsoft Research</font></a>.</h5></li>

								<li><h5>Amongst Top Rated Posters: our work to be featured at <a href="https://www.amazon.science/"><font color="990000">Amazon.Science</font></a> in September.</h5></li>
							  <!--<li><h5>Valuable insights acquired from the dissertation proposal exam.</h5></li>
							  <li><h5>Two papers accepted to <a href="https://2020.ieeeicassp.org/"><font color="990000">ICASSP, Barcelona, Spain, 2020.</font></a></h5></li>	  
							  <!--<li><h5>Gave a talk at Microsoft Research.</h5></li>
							  <li><h5>Effort on neural speech coding followed by <a href="https://www.interspeech2019.org/"><font color="990000">Interspeech acceptance</font></a>,  in Graz, Austria.</h5></li>-->
							<!--</ul>-->
							
							

						<!--
							<h3>AFFILIATION</h3>
							<ul>
							  <!--<li><h5>Ph.D. Candidate in Computer Science and Cognitive Science at <a href="http://www.indiana.edu/"><font color="990000">Indiana University</font></a></h5></li>-->
						<!--	  <li><h5>Research Assistant at Signals & Artificial Ingelligence Group in Engineering <a href="http://saige.sice.indiana.edu/"><font color="990000">(SAIGE)</font></a></h5></li>
							  <li><h5> Applied Scientist Intern at  <a href="https://developer.amazon.com/en-US/alexa/"><font color="990000">Amazon Alexa</font></a> (2020)</h5></li>
							  <li><h5>Machine Learning & Relevance Intern at  <a href="https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin/"><font color="990000">LinkedIn Corporation</font></a> (2018, 2019)</h5></li>								
							</ul>
						-->
							<!--<a class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a>
							<a href="https://scholar.google.com/citations?user=TcK2JhcAAAAJ&hl=en" class="icon brands fa-google-plus"><span class="label">Google+</span></a>
							<p>Machine Learning & Relevance Intern at <a href="https://economicgraph.linkedin.com/">LinkedIn Corporation</a>.</p>-->
						</div>
					</div>
				</div>
			</article>

		<!-- Work -->



		<div id="main-wrapper">
				<div id="main" class="container">
					<div class="row">
						<div class="12u">
							<div class="content">


<hr>
<section>



<hr>
<section>
										

										
										
										
</div></section>





<hr>
<section>									
<h3> Some Project Demos </h3>
<p>My research focuses on designing efficient (or low power) neural network algorithms for the
application to speech/audio coding and enhancement. This is critical, especially in the era of
IoT, for a wide range of devices with limited energy supply (cellphone, hearing aids, smart home
assistants, etc). We resort to not only the power of deep learning as a computational paradigm
but conventional digital signal processing (DSP) techniques as well: an elegant solution is
usually found by bridging these two. For example, we proposed a method to revive the
conventional multi-staged residual coding scheme in neural network for speech coding; we also
presented a collaborative quantization scheme to enable a trainable LPC quantization along
with LPC residual coding. I've also worked on re-engineering psychoacoustics to achieve a more
perceptually salient cost function for neural speech and audio processing. These works have led
to academic publications, patents, and research funding.</p>

<article id="portfolio" class="wrapper style3">
				<div class="container">											
					<div class="row">
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="http://www.kaizhen.us/neural-audio-coding.html" class="image featured"><img src="images/nac-demo.png" alt="" /></a>
								<h3><a href="http://www.kaizhen.us/neural-audio-coding.html">Psychoacoustical Calibration</a></h3>
								<p>Integrating Human Auditory Perception to Neural Codec Optimization</p>
							</article>
						</div>	
						
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="http://www.kaizhen.us/collaborative-quantization.html" class="image featured"><img src="images/cq-demo.png" alt="" /></a>
								<h3><a href="http://www.kaizhen.us/collaborative-quantization.html">Collaborative Quantization</a></h3>
								<p>Incorporated LPC Quantization to Residual Coding</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="https://saige.sice.indiana.edu/research-projects/neural-audio-coding/" class="image featured"><img src="images/cmrl-demo.png" alt="" /></a>
								<h3><a href="https://saige.sice.indiana.edu/research-projects/neural-audio-coding/">Cross Modual Residual Learning (CMRL)</a></h3>
								<p> Serializing Small Autoencoders for Cascaded Quantization</p>
							</article>
						</div>
						<div class="col-4 col-6-medium col-12-small">
							<article class="box style2">
								<a href="http://www.kaizhen.us/dccrn.html" class="image featured"><img src="assets/dccrn-2.png" alt="" /></a>
								<h3><a href="http://www.kaizhen.us/dccrn.html">Dual-Staged Context Aggregation</a></h3>
								<p> Lowering The Delay And Model Complexity via A Hybrid Design </p>
							</article>
						</div>
					</div>
					
				</div>
			</article>

<ul style="list-style-type: disc; margin-left: 1em;"> 


<br>
</div>
</section>
		<!-- Portfolio -->
			
		<!-- Contact -->
		<article id="contact" class="wrapper style4">
				<div class="container medium">
					<header>
						<h2>If interested in my work, </h2>
						<p> zhenk.iu@edu (swap . and @)</p>
					</header>
						
						<div class="col-12">
							<ul class="social">
								<li><a href="https://www.linkedin.com/in/kai-zhen-01b7b5103/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://scholar.google.com/citations?user=TcK2JhcAAAAJ&hl=en" class="icon brands fa-google-plus"><span class="label">Google Scholar</span></a></li>
								<li><a href="https://twitter.com/KaiZhen43594855" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>								
								<!--
								<li><a href="#" class="icon solid fa-rss"><span>RSS</span></a></li>
								<li><a href="#" class="icon brands fa-instagram"><span>Instagram</span></a></li>
								<li><a href="#" class="icon brands fa-foursquare"><span>Foursquare</span></a></li>
								<li><a href="#" class="icon brands fa-skype"><span>Skype</span></a></li>
								<li><a href="#" class="icon brands fa-soundcloud"><span>Soundcloud</span></a></li>
								<li><a href="#" class="icon brands fa-youtube"><span>YouTube</span></a></li>
								<li><a href="#" class="icon brands fa-blogger"><span>Blogger</span></a></li>
								<li><a href="#" class="icon brands fa-flickr"><span>Flickr</span></a></li>
								<li><a href="#" class="icon brands fa-vimeo"><span>Vimeo</span></a></li>
								-->
					<!--		</ul>
							<hr />
							<br>
						</div>
					</div>-->
					<footer>					
						
						<div id="copyright">
						&copy; 2019-2020 by Kai Zhen. All rights reserved.
						Design: <a href="http://html5up.net">HTML5 UP</a>
						</div>
						
					</footer>


				</div>
			</article>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>


	</body>
</html>