



<!--<p><a href="home.html" target="_blank">Street view outside my home.</a></p>-->


<!-- <script type="text/python" src="hello.py"></script>


<p><a href="hello.py" target="_blank">hello</a></p>


<p><a href="http://pages.iu.edu/~zhenk/Snip20150809_5.png" target="_blank">imaggge</a></p>





<a href="http://shijue.me/zone/contest/formula/about" target="_blank">history</a>


-->


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
<link rel="shortcut icon" href="images/pumpkin.jpg">
<!--<link rel="shortcut icon" href="favicon3.ico" type="image/x-icon" >-->
  <title>Kai Zhen - Ph.D. Candidate at Indiana University</title>

  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="description" content="Ph.D. Candidate in Computer Science and Cognitive Science at Indiana University. Future Applied Scientist at Amazon. Proud to Be A Hoosier.">

<!--<link rel="stylesheet" href="assets/css/sub.css" />-->
<link rel="stylesheet" href="/Users/Kai/Documents/personal-info/zhenkaiii.github.io/assets/css/sub.css" />

</head>

  <div align="center">
    <img src="head_2021.jpg" width="750" height="500"  alt="kai">    
     <SPAN STYLE="font-size:.0pt"><BR></SPAN>
    <b><font size="6">Kai Zhen</font></b>
  </div>

<b><font size="4">About Me</font></b><br>
              I'm in my final year of the Ph.D. program, advised by <a href="http://kaizhen.us/cv.pdf">Prof. Minje Kim</a> at Indiana University (<a href="http://kaizhen.us/cv.pdf">CV</a>).              
              My research is mainly on scalable and efficient speech and audio coding via techniques spanning the traditional digital signal processing domain and modern computational paradigm.
              <!--In my view, innovation does not only come from proposing brand new methodologies but reviving the conventional techniques as well.
              This is reflected in most of my projects as an joint effort spanning the traditional digital signal processing domain and modern computational paradigm.-->

              The six-year journey has also endowed me with opportunities including working with great companies such as LinkedIn and Amazon. My next play will be at Amazon Alexa as an applied scientist. 
 <br><br>




<b><font size="4">Publications and Patents</font></b><br>
<ul>

	<li> [J-001] <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<u>Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding</u>," <i>IEEE Signal Processing Letters, vol. 27, pp. 2159-2163, 2020, doi: 10.1109/LSP.2020.3039765.</i>.
<br>
<a href="http://kaizhen.us/neural-audio-coding.html">[demo]</a>
<a href="http://kaizhen.us/pub/zhenk-spl.pdf">[pdf]</a>
<a href="http://kaizhen.us/pub/zhenk2020nac.txt">[bib]</a>
<a href="https://github.com/cocosci/pam-nac">[code]</a></li>

<li> [C-003] <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<u>Efficient And Scalable Neural Residual Waveform Coding with Collaborative Quantization</u>," <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, Barcelona, Spain, May 4-8, 2020. <br><a href="http://kaizhen.us/collaborative-quantization.html">[demo]</a><a href="http://kaizhen.us/pub/zhenk2020cq.pdf">[pdf]</a><a href="http://kaizhen.us/pub/cq.txt">[bib]</a><a href="https://github.com/cocosci/NSC">[code]</a></li>

<li> [C-002] <b>Kai Zhen</b>, Mi Suk Lee, Minje Kim. "<u>A Dual-Staged Context Aggregation Method towards Efficient End-To-End Speech Enhancement</u>,"  <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i>, Barcelona, Spain, May 4-8, 2020. <br><a href="http://kaizhen.us/speechenhancement.html">[demo]</a><a href="http://kaizhen.us/pub/dccrn.txt">[bib]</a></li>


<li> [C-001] <b>Kai Zhen</b>, Jongmo Sung, Mi Suk Lee, Seungkwon Beack, and Minje Kim, "<u>Cascaded Cross-Module Residual Learning towards Lightweight End-to-End Speech Coding</u>," In Proc. Annual Conference of the International Speech Communication Association (Interspeech)</i>, Graz, Austria, September 15-19, 2019. <br><a href="https://saige.sice.indiana.edu/research-projects/neural-audio-coding/">[demo]</a> <a href="http://kaizhen.us/pub/cmrl.txt">[bib]</a>
 </li>



<li> [P-004] Minje Kim, <b>Kai Zhen</b>, Seungkwon Beack, et al, "<u>Collaborative quantization for efficient and scalable neural waveform coding</u>," <i>US Patent Application, US 2020</i>.
</li>

<li> [P-003] Minje Kim, <b>Kai Zhen</b>, Mi Suk Lee, "<u>Apparatus and Method for Speech Processing Using a Densely Connected Hybrid Neural Network</u>," <i>US Patent Application, 2020</i>.
</li>

<li> [P-002] Minje Kim, <b>Kai Zhen</b>, Seungkwon Beack, et al, "<u>Audio Signal Encoding Method and Audio Signal Decoding Method, And Encoder And Decoder Performing the Same</u>," <i>US Patent Application, US20200135220A1</i>.
</li>


<li> [P-001] Minje Kim, Aswin Sivaraman, <b>Kai Zhen</b>, Jongmo Sung, et al, "<u>Audio signal encoding method and apparatus and audio signal decoding method and apparatus using psychoacoustic-based weighted error function</u>," <i>US Patent Application, US20190164052A1</i>.
</li>


<li> [W-004] <b>Kai Zhen</b>, Hieu Duy Nguyen, Feng-Ju (Claire) Chang, Athanasios Mouchtaris. Network Sparsification for On-Device ASR. Amazon Machine Learning Conference (AMLC) Workshop on Network Inference Optimization,2020.</a>
</li>


<li> [W-003] <b>Kai Zhen</b>, Aswin Sivaraman, Jongmo Sung, Minje Kim, "<u>On Psychoacoustically Weighted Cost Functions Towards Resource-efficient Deep Neural Networks for Speech Denoising</u>," <i>The 7th Annual Midwest Cognitive Science Conference</i>, Bloomington, IN, 2018. <a href="http://kaizhen.us/pub/zhen2018psychoacoustically.txt">[bib]</a>
</li>

<li> [W-002] Peter Miksza, Kevin Watson, <b>Kai Zhen</b>, Sanna Wager, Minje Kim, "<u>Relationships between expertsâ€™ subjective ratings of jazz improvisations and computational measures of melodic entropy</u>," <i>The Improvising Brain III: Cultural Variation and Analytical Techniques Symposium</i>, Atlanta, GA, in Feb, 2017.
</li>


<li> [W-001] <b>Kai Zhen</b> and David Crandall, "<u>Finding egocentric image topics through convolutional neural network based representations (extended abstract)</u>," <i>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop on Egocentric Computer Vision</i>, Las Vegas, US, June 26 - July 1, 2016. 
</li>


</ul>




		<!-- Global site tag (gtag.js) - Google Analytics -->


<style type="text/css">.row{border-bottom:solid 1px transparent}.row>*{float:left}.row:after,.row:before{content:"";display:block;clear:both;height:0}.row.uniform>*>:first-child{margin-top:0}.row.uniform>*>:last-child{margin-bottom:0}.\31 2u,.\31 2u\24{width:100%;clear:none;margin-left:0}.\31 1u,.\31 1u\24{width:91.6666666667%;clear:none;margin-left:0}.\31 0u,.\31 0u\24{width:83.3333333333%;clear:none;margin-left:0}.\39 u,.\39 u\24{width:75%;clear:none;margin-left:0}.\38 u,.\38 u\24{width:66.6666666667%;clear:none;margin-left:0}.\37 u,.\37 u\24{width:58.3333333333%;clear:none;margin-left:0}.\36 u,.\36 u\24{width:50%;clear:none;margin-left:0}.\35 u,.\35 u\24{width:41.6666666667%;clear:none;margin-left:0}.\34 u,.\34 u\24{width:33.3333333333%;clear:none;margin-left:0}.\33 u,.\33 u\24{width:25%;clear:none;margin-left:0}.\32 u,.\32 u\24{width:16.6666666667%;clear:none;margin-left:0}.\31 u,.\31 u\24{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24+*,.\31 1u\24+*,.\31 0u\24+*,.\39 u\24+*,.\38 u\24+*,.\37 u\24+*,.\36 u\24+*,.\35 u\24+*,.\34 u\24+*,.\33 u\24+*,.\32 u\24+*,.\31 u\24+*{clear:left;}.\-11u{margin-left:91.6666666667%}.\-10u{margin-left:83.3333333333%}.\-9u{margin-left:75%}.\-8u{margin-left:66.6666666667%}.\-7u{margin-left:58.3333333333%}.\-6u{margin-left:50%}.\-5u{margin-left:41.6666666667%}.\-4u{margin-left:33.3333333333%}.\-3u{margin-left:25%}.\-2u{margin-left:16.6666666667%}.\-1u{margin-left:8.3333333333%}</style><style type="text/css">.container{margin-left:auto;margin-right:auto;width:1200px}.container.\31 25\25{width:100%;max-width:1500px;min-width:1200px}.container.\37 5\25{width:900px}.container.\35 0\25{width:600px}.container.\32 5\25{width:300px}</style><style type="text/css">.row>*{padding:50px 0 0 50px}.row{margin:-50px 0 -1px -50px}.row.uniform>*{padding:50px 0 0 50px}.row.uniform{margin:-50px 0 -1px -50px}.row.\32 00\25>*{padding:100px 0 0 100px}.row.\32 00\25{margin:-100px 0 -1px -100px}.row.uniform.\32 00\25>*{padding:100px 0 0 100px}.row.uniform.\32 00\25{margin:-100px 0 -1px -100px}.row.\31 50\25>*{padding:75px 0 0 75px}.row.\31 50\25{margin:-75px 0 -1px -75px}.row.uniform.\31 50\25>*{padding:75px 0 0 75px}.row.uniform.\31 50\25{margin:-75px 0 -1px -75px}.row.\35 0\25>*{padding:25px 0 0 25px}.row.\35 0\25{margin:-25px 0 -1px -25px}.row.uniform.\35 0\25>*{padding:25px 0 0 25px}.row.uniform.\35 0\25{margin:-25px 0 -1px -25px}.row.\32 5\25>*{padding:12.5px 0 0 12.5px}.row.\32 5\25{margin:-12.5px 0 -1px -12.5px}.row.uniform.\32 5\25>*{padding:12.5px 0 0 12.5px}.row.uniform.\32 5\25{margin:-12.5px 0 -1px -12.5px}.row.\30 \25>*{padding:0}.row.\30 \25{margin:0 0 -1px 0}</style><style type="text/css">.\31 2u\28 global\29,.\31 2u\24\28 global\29{width:100%;clear:none;margin-left:0}.\31 1u\28 global\29,.\31 1u\24\28 global\29{width:91.6666666667%;clear:none;margin-left:0}.\31 0u\28 global\29,.\31 0u\24\28 global\29{width:83.3333333333%;clear:none;margin-left:0}.\39 u\28 global\29,.\39 u\24\28 global\29{width:75%;clear:none;margin-left:0}.\38 u\28 global\29,.\38 u\24\28 global\29{width:66.6666666667%;clear:none;margin-left:0}.\37 u\28 global\29,.\37 u\24\28 global\29{width:58.3333333333%;clear:none;margin-left:0}.\36 u\28 global\29,.\36 u\24\28 global\29{width:50%;clear:none;margin-left:0}.\35 u\28 global\29,.\35 u\24\28 global\29{width:41.6666666667%;clear:none;margin-left:0}.\34 u\28 global\29,.\34 u\24\28 global\29{width:33.3333333333%;clear:none;margin-left:0}.\33 u\28 global\29,.\33 u\24\28 global\29{width:25%;clear:none;margin-left:0}.\32 u\28 global\29,.\32 u\24\28 global\29{width:16.6666666667%;clear:none;margin-left:0}.\31 u\28 global\29,.\31 u\24\28 global\29{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24\28 global\29+*,.\31 1u\24\28 global\29+*,.\31 0u\24\28 global\29+*,.\39 u\24\28 global\29+*,.\38 u\24\28 global\29+*,.\37 u\24\28 global\29+*,.\36 u\24\28 global\29+*,.\35 u\24\28 global\29+*,.\34 u\24\28 global\29+*,.\33 u\24\28 global\29+*,.\32 u\24\28 global\29+*,.\31 u\24\28 global\29+*{clear:left;}.\-11u\28 global\29{margin-left:91.6666666667%}.\-10u\28 global\29{margin-left:83.3333333333%}.\-9u\28 global\29{margin-left:75%}.\-8u\28 global\29{margin-left:66.6666666667%}.\-7u\28 global\29{margin-left:58.3333333333%}.\-6u\28 global\29{margin-left:50%}.\-5u\28 global\29{margin-left:41.6666666667%}.\-4u\28 global\29{margin-left:33.3333333333%}.\-3u\28 global\29{margin-left:25%}.\-2u\28 global\29{margin-left:16.6666666667%}.\-1u\28 global\29{margin-left:8.3333333333%}.\31 2u\28 desktop\29,.\31 2u\24\28 desktop\29{width:100%;clear:none;margin-left:0}.\31 1u\28 desktop\29,.\31 1u\24\28 desktop\29{width:91.6666666667%;clear:none;margin-left:0}.\31 0u\28 desktop\29,.\31 0u\24\28 desktop\29{width:83.3333333333%;clear:none;margin-left:0}.\39 u\28 desktop\29,.\39 u\24\28 desktop\29{width:75%;clear:none;margin-left:0}.\38 u\28 desktop\29,.\38 u\24\28 desktop\29{width:66.6666666667%;clear:none;margin-left:0}.\37 u\28 desktop\29,.\37 u\24\28 desktop\29{width:58.3333333333%;clear:none;margin-left:0}.\36 u\28 desktop\29,.\36 u\24\28 desktop\29{width:50%;clear:none;margin-left:0}.\35 u\28 desktop\29,.\35 u\24\28 desktop\29{width:41.6666666667%;clear:none;margin-left:0}.\34 u\28 desktop\29,.\34 u\24\28 desktop\29{width:33.3333333333%;clear:none;margin-left:0}.\33 u\28 desktop\29,.\33 u\24\28 desktop\29{width:25%;clear:none;margin-left:0}.\32 u\28 desktop\29,.\32 u\24\28 desktop\29{width:16.6666666667%;clear:none;margin-left:0}.\31 u\28 desktop\29,.\31 u\24\28 desktop\29{width:8.3333333333%;clear:none;margin-left:0}.\31 2u\24\28 desktop\29+*,.\31 1u\24\28 desktop\29+*,.\31 0u\24\28 desktop\29+*,.\39 u\24\28 desktop\29+*,.\38 u\24\28 desktop\29+*,.\37 u\24\28 desktop\29+*,.\36 u\24\28 desktop\29+*,.\35 u\24\28 desktop\29+*,.\34 u\24\28 desktop\29+*,.\33 u\24\28 desktop\29+*,.\32 u\24\28 desktop\29+*,.\31 u\24\28 desktop\29+*{clear:left;}.\-11u\28 desktop\29{margin-left:91.6666666667%}.\-10u\28 desktop\29{margin-left:83.3333333333%}.\-9u\28 desktop\29{margin-left:75%}.\-8u\28 desktop\29{margin-left:66.6666666667%}.\-7u\28 desktop\29{margin-left:58.3333333333%}.\-6u\28 desktop\29{margin-left:50%}.\-5u\28 desktop\29{margin-left:41.6666666667%}.\-4u\28 desktop\29{margin-left:33.3333333333%}.\-3u\28 desktop\29{margin-left:25%}.\-2u\28 desktop\29{margin-left:16.6666666667%}.\-1u\28 desktop\29{margin-left:8.3333333333%}</style>
		



<br>
<b><font size="4">Positions Held</font></b><br><br>

<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/iu.png" border="0" width="50%">
</div>
<div class="9u">

<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Research Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Jan. 2018 - present</li>
		<li>Project: efficient end-to-end neural audio coding system</li>
		<li>Research group: <a href="http://saige.sice.indiana.edu/" target="_blank">Signals and AI Group in Engineering (SAIGE)</a></li>
	</ul>
</li></ul>	

<ul style="list-style-type: disc; margin-left: 2em;"> 
<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Teaching Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2015 - Dec. 2017</li>
		<li><a href="https://cs.indiana.edu/" target="_blank">Department of Computer Science</a> <br>(CSCI-C 343, CSCI-B 551, CSCI-B 657)</li>
		<li><a href="https://engineering.indiana.edu/" target="_blank">Intelligent Systems Engineering Department</a> <br>(ENGR E511, ENGR E533)</li>
	</ul>
</li></ul>
</div>
</div>



<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/amazon.png" border="0" width="50%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://developer.amazon.com/en-US/alexa/science" target="_blank">Amazon</a>: <b>Applied Scientist Intern</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2020 - Aug. 2020</li>						
		<li>Alexa Edge ML team</li>
		<li>Mentor: Hieu Duy Nguyen, Feng-ju (Claire) Chang</li>
		<li>Manager: Athanasios Mouchtaris</li>
		<li>Project: network compression for on-device ASR solutions</li>	
</li>							
						
	</ul>
</ul>	
</div>
</div>


<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/linkedin.svg" border="0" width="50%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2019 - Aug. 2019, Mountain View, CA </li>						
		<li>Ads AI group</li>							
		<li>Mentor: Lijun Peng, Hiroto Udagawa</li>		
		<li>Manager: Sara Smoot</li>							
		<li>Project: ads response rate prediction in wide-n-deep estimators and BERT</li>	
	</ul>
</li></ul>	
</div>
</div>

<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/linkedin.svg" border="0" width="50%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: 2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2018 - Aug. 2018, New York City, NY </li>						
		<li>Company standardization group</li>							
		<li>Mentor: Deirdre Hogan</li>	
		<li>Manager: Xiaoqiang Luo</li>	
		<li>Project: relevance ranking for resume builder with deep neural networks</li>	
	</ul>
</li></ul>	
</div>
</div>

<hr>

						
<!--

<br>
<b><font size="4">Education</font></b><br><br>


<div class="row">


<!--<br><br>
<h3><strong>Contact</strong></h3>
<p>
  Email: zhenk@iu.edu  <br>
  Address: 700 N. Woodlawn Ave. Luddy Hall, Bloomington, Indiana, 47404.
<br>
 GoStats Simple HTML Based Code <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=CED9&d=q-glD7r36S7FadlnyzQ4gHE0XpUsa2F29LAAnJ8bj0U"></script>-->




</body>
</html>
