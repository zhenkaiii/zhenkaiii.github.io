



<!--<p><a href="home.html" target="_blank">Street view outside my home.</a></p>-->


<!-- <script type="text/python" src="hello.py"></script>


<p><a href="hello.py" target="_blank">hello</a></p>


<p><a href="http://pages.iu.edu/~zhenk/Snip20150809_5.png" target="_blank">imaggge</a></p>





<a href="http://shijue.me/zone/contest/formula/about" target="_blank">history</a>


-->


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>



<script>
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 33.33%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
</script>

<link rel="shortcut icon" href="images/pumpkin.jpg">
<!--<link rel="shortcut icon" href="favicon3.ico" type="image/x-icon" >-->
  <title>Kai Zhen</title>

  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="description" content="Ph.D. in Computer Science and Cognitive Science at Indiana University. Future Applied Scientist at Amazon. Proud to Be A Hoosier.">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link rel="stylesheet" href="assets/css/arlington.css" />
<link rel="stylesheet" href="assets/css/washingtonpost.css" />
<link rel="stylesheet" href="assets/css/sub.css" />






<!--
<link rel="stylesheet"  media="screen and (max-width: 1680px)" href="assets/css/sub.css" />
<link rel="stylesheet" href="css/skel.css" />
<link rel="stylesheet" href="css/style.css" />
<link rel="stylesheet" href="css/style-desktop.css" />
<link rel="stylesheet" type="text/css" href="assets/css/fibonacci.css">
<link rel="stylesheet" href="assets/css/sub.css" />


	<link rel="stylesheet"
	      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
	<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
</head>
-->



  <div align="center">
    <img src="head_2021.jpg" style="width: 55vw; min-width: 330px;">
<!--<img src="head_2021.jpg" style="width: 45vw; min-width: 530px;">-->
	  <!--<img src="61513716428b3_v2.png" style="width: 40vw; min-width: 510px;opacity:0.9">-->

	  <br>
<!--	  <img src="woo2.jpg" style="width: 25vw; min-width: 330px;"><br>-->
     <SPAN STYLE="font-size:.5pt"><BR></SPAN>
    <b><font size="7">Kai Zhen</font></b><br><br>
		  <navline>
			  <b class="label label-journal"><a id="selected" href="index.html">Home</a></b>
  <b class="label label-journal"><a href="zhenk_cv.pdf">CV (PDF)</a></b>
  <b class="label label-journal"><a href="publications.html">Publications</a></b>
  <b class="label label-journal"><a href="demos.html">Demos</a></b>
  <b class="label label-journal"><a href="presentations.html">Presentations</a></b>
		  </navline>

  </div>






<br>
<div id="container">
<div id="home_target" style="position: relative; top: -50px;"></div>
<p>
	<!--<b><font size="4">About Me</font></b><br><br>-->
	Kai Zhen earned his Ph.D. in <a href="https://cs.indiana.edu/">Computer Science </a> and <a href="https://cogs.indiana.edu/">Cognitive Science</a> (joint degree) from <a href="https://iub.edu"> Indiana University</a>. In the course
	of his Ph.D. studies, he conducted research on human learning inspired lightweight models for speech/audio waveform coding.
	He is now an applied scientist for <a href="https://developer.amazon.com/en-US/alexa">Alexa Speech</a> at Amazon.com, Inc.
	His job responsibility is to make on-device speech recognition models lightweight and accurate
	to improve customer satisfaction.
	<br><br>
	Email: kaizhen723.gmail@com<br>
	<a href="zhenk_cv.pdf">Curriculum Vitae (as of 09/2021)</a>
<br>



</p>

</div>




<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="assets/css/arlington.css" />
<link rel="stylesheet" href="assets/css/washingtonpost.css" />
<link rel="stylesheet" href="assets/css/sub.css" />

      <div align="center">
     <SPAN STYLE="font-size:.5pt"><BR></SPAN>



  </div>


<b><font size="5">Publications</font></b><br><br>
<!--<b><font size="4">Publications</font></b>-->
<br>
<em>
<b class="label label-journal">Journal Articles </b>&nbsp
<b class="label label-conference">Conference Proceedings </b>&nbsp
<b class="label label-patent">Patents </b>&nbsp
<b class="label label-workshop">Workshop Papers </b>
</em>
<br><br>

<b><font size="4">===2021===</font></b><br><br>

<p align="justify">
	 <b class="label label-journal">J-002</b> <b>Kai Zhen</b>, Jongmo Sung, Mi Suk Lee, Seungkwon Beack, Minje Kim, "<b>Scalable and Efficient Neural Speech Coding: A Hybrid Design," <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing (IEEE/ACM TASLP), 2021 </i></b>.
<br>
	<a href="http://kaizhen.us/pub/zhenk-taslp-2021-sc.pdf">[pdf]</a>

</p>

<p align="justify">
    <b class="label label-patent">P-005</b> Mi Suk Lee, Seung Kwon Beack, Jongmo Sung, Tae Jin Lee, Jin Soo Choi, Minje Kim, <b>Kai Zhen</b>, "<b>Method and apparatus for processing audio signal</b>," <i>U.S. Patent Application US20210233547A1</i>.
</p>

<p align="justify">
    <b class="label label-patent">P-004</b> Minje Kim, <b>Kai Zhen</b>, Mi Suk Lee, Seung Kwon Beack, Jongmo Sung, Tae Jin Lee, Jin Soo Choi "<b>Residual Coding Method of Linear Prediction Coding Coefficient Based on Collaborative Quantization, and Computing Device for Performing the Method</b>," <i>U.S. Patent Application No. 17/098,090</i>.
</p>

<p align="justify">
 <b class="label label-conference">C-005</b>  <b>Kai Zhen</b>, Hieu Duy Nguyen, Feng-Ju (Claire) Chang, Athanasios Mouchtaris, and Ariya Rastrow, "<b>Sparsification via Compressed Sensing for Automatic Speech Recognition," <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i></b>, Toronto, ON, Canada, June 6-12, 2021. <br>
<!--<a href="http://kaizhen.us/pub/cs-poster.png">[poster]</a>-->
	<a href="https://assets.amazon.science/d1/3e/1301067541d0ac20abbcfe0d93d5/sparsification-via-compressed-sensing-for-automatic-speech-recognition.pdf">[pdf]</a> <br><i>&#42;from the summer internship with Amazon</i>
</p>

<p>
<b class="label label-conference">C-004</b>  Haici Yang, <b>Kai Zhen</b>, Seungkwon Beack, Minje Kim, "<b>Source-Aware Neural Speech Coding for Noisy Speech Compression," <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i></b>, Toronto, ON, Canada, June 6-12, 2021. <br>
<a href="https://arxiv.org/pdf/2008.12889.pdf">[pdf]</a>
</p>

<br><b><font size="4">===2020===</font></b><br><br>

<p align="justify">
	 <b class="label label-journal">J-001</b> <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<b>Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding," <i>IEEE Signal Processing Letters</b>, vol. 27, pp. 2159-2163, 2020, doi: 10.1109/LSP.2020.3039765.</i>.
<br>
<a href="http://kaizhen.us/neural-audio-coding.html">[demo]</a>
<a href="http://kaizhen.us/pub/zhenk-spl.pdf">[pdf]</a>
<a href="https://github.com/cocosci/pam-nac">[code]</a></p>


<p align="justify">
 <b class="label label-conference">C-003</b> <b>Kai Zhen</b>, Mi Suk Lee, Jongmo Sung, Seungkwon Beack, and Minje Kim, "<b>Efficient and Scalable Neural Residual Waveform Coding with Collaborative Quantization," <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i></b>, Barcelona, Spain, May 4-8, 2020. <br>
	<a href="http://kaizhen.us/collaborative-quantization.html">[demo]</a>
	<a href="http://kaizhen.us/pub/zhenk2020cq.pdf">[pdf]</a>
	<!--<a href="http://kaizhen.us/pub/cq.txt">[bib]</a>-->
	<a href="https://github.com/cocosci/NSC">[code]</a></p>

<p align="justify">
 <b class="label label-conference">C-002</b> <b>Kai Zhen</b>, Mi Suk Lee, Minje Kim. "<b>A Dual-Staged Context Aggregation Method towards Efficient End-To-End Speech Enhancement,"  <i>in Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</i></b>, Barcelona, Spain, May 4-8, 2020. <br>
	<a href="http://kaizhen.us/speechenhancement.html">[demo]</a>
	<a href="http://kaizhen.us/pub/zhenk2020dccrn.pdf">[pdf]</a>
<!--	<a href="http://kaizhen.us/pub/dccrn.txt">[bib]</a>-->
</p>




<p align="justify">
 <b class="label label-patent">P-003</b> Minje Kim, <b>Kai Zhen</b>, Mi Suk Lee, "<b>Apparatus and Method for Speech Processing Using a Densely Connected Hybrid Neural Network</b>," <i>US Patent Application, 2020</i>.
</p>

<p align="justify">
 <b class="label label-patent">P-002</b> Minje Kim, <b>Kai Zhen</b>, Seungkwon Beack, et al, "<b>Audio Signal Encoding Method and Audio Signal Decoding Method, And Encoder And Decoder Performing the Same</b>," <i>US Patent Application, US20200135220A1</i>.
</p>

<p align="justify">
 <b class="label label-workshop">W-004</b> <b>Kai Zhen</b>, Hieu Duy Nguyen, Feng-Ju (Claire) Chang, Athanasios Mouchtaris. <b>Network Sparsification for On-Device ASR</b>. <i>Amazon Machine Learning Conference (AMLC) Workshop on Network Inference Optimization, 2020.</i></a>
</p>


<br><b><font size="4">===2019 and earlier===</font></b><br><br>

<p align="justify">
 <b class="label label-conference">C-001</b> <b>Kai Zhen</b>, Jongmo Sung, Mi Suk Lee, Seungkwon Beack, and Minje Kim, "<b>Cascaded Cross-Module Residual Learning towards Lightweight End-to-End Speech Coding," <i>In Proc. Annual Conference of the International Speech Communication Association (Interspeech)</i></b>, Graz, Austria, September 15-19, 2019. <br>
	<a href="https://saige.sice.indiana.edu/research-projects/neural-audio-coding/">[demo]</a>
	<a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1816.pdf">[pdf]</a>
	<!--<a href="http://kaizhen.us/pub/cmrl.txt">[bib]</a>-->
 </p>


<p align="justify">
 <b class="label label-patent">P-001</b> Minje Kim, Aswin Sivaraman, <b>Kai Zhen</b>, Jongmo Sung, et al, "<b>Audio signal encoding method and apparatus and audio signal decoding method and apparatus using psychoacoustic-based weighted error function</b>," <i>US Patent Application, US20190164052A1</i>.
</p>


<p align="justify">
 <b class="label label-workshop">W-003</b> <b>Kai Zhen</b>, Aswin Sivaraman, Jongmo Sung, Minje Kim, "<b>On Psychoacoustically Weighted Cost Functions Towards Resource-efficient Deep Neural Networks for Speech Denoising</b>," <i>The 7th Annual Midwest Cognitive Science Conference</i>, Bloomington, IN, 2018.<br>
	<a href="https://arxiv.org/pdf/1801.09774.pdf">[pdf]</a>

</p>

<p align="justify">
 <b class="label label-workshop">W-002</b> Peter Miksza, Kevin Watson, <b>Kai Zhen</b>, Sanna Wager, Minje Kim, "<b>Relationships between experts' subjective ratings of jazz improvisations and computational measures of melodic entropy</b>," <i>The Improvising Brain III: Cultural Variation and Analytical Techniques Symposium</i>, Atlanta, GA, in Feb, 2017.
</p>

<p align="justify">
 <b class="label label-workshop">W-001</b> <b>Kai Zhen</b> and David Crandall, "<b>Finding egocentric image topics through convolutional neural network based representations (extended abstract)</b>," <i>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop on Egocentric Computer Vision</i>, Las Vegas, US, June 26 - July 1, 2016.
</p>




<br>
<b><font size="5">Positions Held</font></b><br><br>


	<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/amazon.png" border="0" width="50%">
</div>
<div class="9u">

<ul style="list-style-type: disc; margin-left: -2em;">
	<li><a href="https://developer.amazon.com/en-US/alexa/science" target="_blank">Amazon</a>: <b>Applied Scientist</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;">
		<li>Apr. 2021 - present</li>
		<li>Alexa Machine Learning</li>
</li>
</ul>
	<li><a href="https://developer.amazon.com/en-US/alexa/science" target="_blank">Amazon</a>: <b>Applied Scientist Intern</b></li>
	<ul style="list-style-type: circle; margin-left: 2em;">
		<li>May. 2020 - Aug. 2020</li>
		<li>Alexa Edge ML team</li>
		<li>Mentor: Hieu Duy Nguyen, Feng-ju (Claire) Chang</li>
		<li>Manager: Athanasios Mouchtaris</li>
		<li>Project: network compression for on-device ASR solutions</li>
</li>

	</ul>
</ul>
</div>
</div>


	<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/iu.png" border="0" width="50%">
</div>
<div class="9u">

<ul style="list-style-type: disc; margin-left: -2em;"> 
	<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Research Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Jan. 2018 - Mar. 2021</li>
		<li>Project: efficient end-to-end neural audio coding system</li>
		<li>Research group: <a href="http://saige.sice.indiana.edu/" target="_blank">Signals and AI Group in Engineering (SAIGE)</a></li>
	</ul>
</li></ul>	

<ul style="list-style-type: disc; margin-left: -2em;"> 
<li><a href="http://indiana.edu/" target="_blank">Indiana University</a>: <b>Teaching Assistant</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>Aug. 2015 - Dec. 2017</li>
		<li><a href="https://cs.indiana.edu/" target="_blank">Department of Computer Science</a> <br>(CSCI-C 343, CSCI-B 551, CSCI-B 657)</li>
		<li><a href="https://engineering.indiana.edu/" target="_blank">Intelligent Systems Engineering Department</a> <br>(ENGR E511, ENGR E533)</li>
	</ul>
</li></ul>
</div>
</div>






<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<img src="assets/linkedin.svg" border="0" width="50%">
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: -2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2019 - Aug. 2019, Mountain View, CA </li>						
		<li>Ads AI group</li>							
		<li>Mentor: Lijun Peng, Hiroto Udagawa</li>		
		<li>Manager: Sara Smoot</li>							
		<li>Project: ads response rate prediction in wide-n-deep estimators and BERT</li>	
	</ul>
</li></ul>	
</div>
</div>

<div class="row">
<!-- <div class="0.3u"> </div> -->
<div class="3u" align="center">
	<!--<img src="assets/linkedin.svg" border="0" width="50%">-->
</div>
<div class="9u">
<ul style="list-style-type: disc; margin-left: -2em;"> 
	<li><a href="https://economicgraph.linkedin.com/research#all" target="_blank">LinkedIn Corporation</a>: <b>Machine Learning & Relevance Intern</b>
	<ul style="list-style-type: circle; margin-left: 2em;"> 
		<li>May. 2018 - Aug. 2018, New York City, NY </li>						
		<li>Company standardization group</li>							
		<li>Mentor: Deirdre Hogan</li>	
		<li>Manager: Xiaoqiang Luo</li>	
		<li>Project: relevance ranking for resume builder with deep neural networks</li>	
	</ul>
</li></ul>	
</div>
</div>

<br><br>
	<b><font size="5">Professional Activities</font></b>
	<br><br>
		<b><font size="4.8">Conference Reviewer</font></b>


<ul style="list-style-type: circle; margin-left: 2em;">
	<li><i>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) - 2019 to 2022</i></li>
	<li><i>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</i>
	<ul style=" margin-left: 2em;">
		<li>Technical Program Committee Member (2021-2022)</li></ul>
	</li>
	<li><i>IEEE International Conference on Data Mining (ICDM), 2020</i></li>
	<li><i>Association for the Advancement of Artificial Intelligence (AAAI) - 2017, 2018</i></li>
	</ul>
	<b><font size="4.8">Journal Reviewer</font></b>
<ul style="list-style-type: circle; margin-left: 2em;">
		<li><i>IEEE MultiMedia</i></li>
	<li><i>European Association for Signal Processing (EURASIP) Journal on Audio, Speech, and Music Processing</i></li>

	</ul>

<hr>

<!--
<div align="center">
<section id="custom_html-7" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><b><font size="4">Visitor Statistics</font></b><div class="textwidget custom-html-widget">
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=jGdG1k5xplNC_7uIAOKPmrstD74VXasxYxZ3i0GfUlk"></script></div></div>
</section>
</div>
-->
	<div align="center">
	<section id="custom_html-7" class="widget_text widget widget_custom_html">
		<!--<div class="widget_text widget-wrap">
		<div class="textwidget custom-html-widget"></div></div>-->
		<script type="text/javascript" id="" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=1&t=n&d=jGdG1k5xplNC_7uIAOKPmrstD74VXasxYxZ3i0GfUlk"></script>
	</section>
		</div>
 <footer> <small>&copy; Copyright 2021, Kai Zhen</small> </footer>

<!--

<p>
  Email: zhenk@iu.edu  <br>
  Address: 700 N. Woodlawn Ave. Luddy Hall, Bloomington, Indiana, 47404.
</p>
	-->



</body>
</html>
